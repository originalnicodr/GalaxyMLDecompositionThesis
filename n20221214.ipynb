{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef443fdd-226b-4511-8d80-ecd9fc5683f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normalized_star_energy', 'eps', 'eps_r']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import galaxychop as gchop\n",
    "\n",
    "\n",
    "#gal = gchop.preproc.center_and_align(gchop.io.read_hdf5(\"tests/datasets/gal394242.h5\"))\n",
    "#gal = gchop.preproc.center_and_align(gchop.io.read_hdf5(\"tests/datasets/galaxy_TNG_2.h5\"))\n",
    "\n",
    "#comp = gchop.models.AutoGaussianMixture(n_jobs=-2).decompose(gal)\n",
    "\n",
    "#gchop.models.GaussianMixture().get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07526877-2659-4518-8e93-95813728f0bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'circ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#gal.plot.pairplot(attributes=[\"x\", \"y\", \"z\"], labels=comp, lmap={0: \"disk\", 1: \"halo\"})\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#gal.plot.circ_pairplot(labels=comp, attributes=['normalized_star_energy', 'eps', 'eps_r'])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m#circ = gchop.preproc.jcirc(gal)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m#circ.as_dict().keys()\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m circ\u001b[39m.\u001b[39mas_dict()\u001b[39m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'circ' is not defined"
     ]
    }
   ],
   "source": [
    "#gal.plot.pairplot(attributes=[\"x\", \"y\", \"z\"], labels=comp, lmap={0: \"disk\", 1: \"halo\"})\n",
    "#gal.plot.circ_pairplot(labels=comp, attributes=['normalized_star_energy', 'eps', 'eps_r'])\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "#comp.describe()\n",
    "#circ = gchop.preproc.jcirc(gal)\n",
    "#circ.as_dict().keys()\n",
    "#circ.as_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "135cedac-a2df-46b5-b6d0-762ce5031f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Particles</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Deterministic mass</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Probabilistic mass</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Fraction</th>\n",
       "      <th>Size</th>\n",
       "      <th>Fraction</th>\n",
       "      <th>Size</th>\n",
       "      <th>Fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Halo</th>\n",
       "      <td>5196</td>\n",
       "      <td>0.139550</td>\n",
       "      <td>5.145612e+09</td>\n",
       "      <td>0.138092</td>\n",
       "      <td>5.847603e+09</td>\n",
       "      <td>0.156932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bulge</th>\n",
       "      <td>5400</td>\n",
       "      <td>0.145029</td>\n",
       "      <td>5.046786e+09</td>\n",
       "      <td>0.135440</td>\n",
       "      <td>5.142812e+09</td>\n",
       "      <td>0.138017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cold disk</th>\n",
       "      <td>8088</td>\n",
       "      <td>0.217221</td>\n",
       "      <td>8.704654e+09</td>\n",
       "      <td>0.233606</td>\n",
       "      <td>8.257483e+09</td>\n",
       "      <td>0.221605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warm disk</th>\n",
       "      <td>18550</td>\n",
       "      <td>0.498201</td>\n",
       "      <td>1.836506e+10</td>\n",
       "      <td>0.492862</td>\n",
       "      <td>1.801422e+10</td>\n",
       "      <td>0.483446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Particles           Deterministic mass           Probabilistic mass  \\\n",
       "               Size  Fraction               Size  Fraction               Size   \n",
       "Halo           5196  0.139550       5.145612e+09  0.138092       5.847603e+09   \n",
       "Bulge          5400  0.145029       5.046786e+09  0.135440       5.142812e+09   \n",
       "Cold disk      8088  0.217221       8.704654e+09  0.233606       8.257483e+09   \n",
       "Warm disk     18550  0.498201       1.836506e+10  0.492862       1.801422e+10   \n",
       "\n",
       "                     \n",
       "           Fraction  \n",
       "Halo       0.156932  \n",
       "Bulge      0.138017  \n",
       "Cold disk  0.221605  \n",
       "Warm disk  0.483446  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1022f741-e32b-47b5-b9c3-85bd13961f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd2b1ab1-0518-48b1-8bf8-4786b9d0ffb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['normalized_star_energy', 'normalized_star_Jz', 'eps', 'eps_r'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3a67c17-2c92-4222-a81c-97486800007a",
   "metadata": {},
   "source": [
    "- Hacete el cluster jerarquico\n",
    "- Barre 2,3,4 y 5 componentes ['normalized_star_energy', 'eps', 'eps_r']\n",
    "- Barre usar todas combinaciones de\n",
    "- Sacale todas las metricas que ya tenes\n",
    "- Graficalo\n",
    "- Y todo comparalo paso a paso con Si los elementos son 2 con JHistogram, mas de eso comparalo con AutoGausian\n",
    "- Acordate de fijar semillas siempre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc5e256-928a-46d4-8c29-db273f9bcd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "from typing import Optional, List\n",
    "import numpy as np\n",
    "\n",
    "class ClusteringMethod:\n",
    "    pass\n",
    "class HierarchicalClustering(ClusteringMethod):\n",
    "    def __init__(self, comp):\n",
    "        self._comp = comp\n",
    "        self._has_probs = comp.probabilities is not None\n",
    "        \n",
    "    def run(self, n_clusters: int = 4, linkage: str = 'ward', attributes: Optional[List[int]] = None):\n",
    "        attribute_indeces = range(0, len(self._comp.attributes)) if attributes is None else attributes\n",
    "        galaxy_data = self._prepare_data(attribute_indeces)\n",
    "        clustering = sklearn.cluster.AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
    "        clustering.fit(galaxy_data)\n",
    "        \n",
    "        return np.array(clustering.labels_)\n",
    "    \n",
    "    def run_all(self, linkage: str = 'ward'):\n",
    "        all_attributes = self._comp.attributes\n",
    "        results = []\n",
    "        index = []\n",
    "        x = 0\n",
    "        for n, amount_attributes in enumerate(range(1, len(all_attributes)+1)):\n",
    "            combined_attributes = list(itertools.combinations(enumerate(all_attributes), amount_attributes))\n",
    "            for attributes in combined_attributes:\n",
    "                index.append(attributes)\n",
    "                results.append([])\n",
    "                for y, n_clusters in enumerate([2,3,4]):\n",
    "                    attribute_indices = [attribute[0] for attribute in attributes]\n",
    "                    results[x].append(self.run(n_clusters = n_clusters, attributes = attribute_indices))\n",
    "                x=x+1\n",
    "        \n",
    "        index = list(map(lambda a: str(tuple(map(lambda b: b[1], a))), index))\n",
    "        return pd.DataFrame(results,\n",
    "        index=pd.Index(index, name='Attributes'),\n",
    "        columns=pd.Index([2,3,4], name='n_clusters'))\n",
    "    \n",
    "    def _prepare_data(self, attribute_indices: List[int]):\n",
    "        data = [[t[i] for i in attribute_indices] for t in self._comp.x_clean]\n",
    "        attributes = [self._comp.attributes[i] for i in attribute_indices]\n",
    "        \n",
    "        galaxy_data = pd.DataFrame(data, columns = attributes)\n",
    "        #Reduced data set to be able to test stuff locally\n",
    "        galaxy_data = galaxy_data.head(100)\n",
    "        return galaxy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f20b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import galaxychop as gchop\n",
    "\n",
    "gal = gchop.preproc.center_and_align(gchop.io.read_hdf5(\"tests/datasets/gal394242.h5\"))\n",
    "\n",
    "comp = gchop.models.AutoGaussianMixture(n_jobs=-2).decompose(gal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "28f1f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hclustering = HierarchicalClustering(comp)\n",
    "#hclustering.run()\n",
    "#clustering_results = hclustering.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f09dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Internal:\n",
    "    \"\"\"Internal evaluation indexes.\n",
    "    \n",
    "    This class contains methods used for internal evaluation of clustering results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    comp: Components\n",
    "        The components of a galaxy.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, comp):\n",
    "        self._comp = comp\n",
    "        self._has_probs = comp.probabilities is not None\n",
    "\n",
    "    def silhouette(self, labels, **kwars):\n",
    "        \"\"\"The silhouette value is a measure of how similar an object is to its own cluster (cohesion)\n",
    "        compared to other clusters (separation). The silhouette ranges from âˆ’1 to +1,\n",
    "        where a high value indicates that the object is well matched to its own cluster and\n",
    "        poorly matched to neighboring clusters. If most objects have a high value,\n",
    "        then the clustering configuration is appropriate. If many points have a low or negative value,\n",
    "        then the clustering configuration may have too many or too few clusters.\n",
    "        \"\"\"\n",
    "        \n",
    "        #Reduced data set to be able to test stuff locally\n",
    "        galaxy_data = pd.DataFrame(self._comp.x_clean, columns = self._comp.attributes).head(100)\n",
    "        return sklearn.metrics.silhouette_score(galaxy_data, labels, **kwars)\n",
    "\n",
    "    def davies_bouldin(self, labels, **kwars):\n",
    "        \"\"\"Validates how well the clustering has been done is made using quantities and\n",
    "        features inherent to the dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        #Reduced data set to be able to test stuff locally\n",
    "        galaxy_data = pd.DataFrame(self._comp.x_clean, columns = self._comp.attributes).head(100)\n",
    "        return sklearn.metrics.davies_bouldin_score(galaxy_data, labels, **kwars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18997ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal evaluation: attributes='normalized_star_energy', n_clusters=2\n",
      "Silhouette:  0.14661494321943136\n",
      "Davies Bouldin:  2.3750366488862755\n",
      "Internal evaluation: attributes='normalized_star_energy', n_clusters=3\n",
      "Silhouette:  -0.033392931529375385\n",
      "Davies Bouldin:  3.773401328217627\n",
      "Internal evaluation: attributes='normalized_star_energy', n_clusters=4\n",
      "Silhouette:  -0.05205638286980453\n",
      "Davies Bouldin:  19.23301301245819\n",
      "Internal evaluation: attributes='eps', n_clusters=2\n",
      "Silhouette:  0.36219074913930727\n",
      "Davies Bouldin:  1.0492050903541206\n",
      "Internal evaluation: attributes='eps', n_clusters=3\n",
      "Silhouette:  0.29769338203660356\n",
      "Davies Bouldin:  1.1408448875408992\n",
      "Internal evaluation: attributes='eps', n_clusters=4\n",
      "Silhouette:  0.23832918224694713\n",
      "Davies Bouldin:  1.3328401769480185\n",
      "Internal evaluation: attributes='eps_r', n_clusters=2\n",
      "Silhouette:  0.3479039143915803\n",
      "Davies Bouldin:  1.436308611433696\n",
      "Internal evaluation: attributes='eps_r', n_clusters=3\n",
      "Silhouette:  0.18025039820354993\n",
      "Davies Bouldin:  1.78337689904439\n",
      "Internal evaluation: attributes='eps_r', n_clusters=4\n",
      "Silhouette:  0.09682942585320344\n",
      "Davies Bouldin:  2.3142306983857313\n",
      "Internal evaluation: attributes='normalized_star_energy', 'eps' n_clusters=2\n",
      "Silhouette:  0.3644591005213234\n",
      "Davies Bouldin:  1.0385581985436316\n",
      "Internal evaluation: attributes='normalized_star_energy', 'eps' n_clusters=3\n",
      "Silhouette:  0.3161788023073164\n",
      "Davies Bouldin:  1.0045156107060855\n",
      "Internal evaluation: attributes='normalized_star_energy', 'eps' n_clusters=4\n",
      "Silhouette:  0.2882112778710159\n",
      "Davies Bouldin:  1.117713268140147\n",
      "Internal evaluation: attributes='normalized_star_energy', 'eps_r' n_clusters=2\n",
      "Silhouette:  0.3479039143915803\n",
      "Davies Bouldin:  1.436308611433696\n",
      "Internal evaluation: attributes='normalized_star_energy', 'eps_r' n_clusters=3\n",
      "Silhouette:  0.18025039820354993\n",
      "Davies Bouldin:  1.78337689904439\n",
      "Internal evaluation: attributes='normalized_star_energy', 'eps_r' n_clusters=4\n",
      "Silhouette:  0.09682942585320344\n",
      "Davies Bouldin:  2.3142306983857313\n",
      "Internal evaluation: attributes='eps', 'eps_r' n_clusters=2\n",
      "Silhouette:  0.3533233889165955\n",
      "Davies Bouldin:  1.0767255652685122\n",
      "Internal evaluation: attributes='eps', 'eps_r' n_clusters=3\n",
      "Silhouette:  0.35073944239426263\n",
      "Davies Bouldin:  0.8593061365378304\n",
      "Internal evaluation: attributes='eps', 'eps_r' n_clusters=4\n",
      "Silhouette:  0.3897502484951783\n",
      "Davies Bouldin:  0.8616048993639427\n",
      "Internal evaluation: attributes='normalized_star_energy', 'eps', 'eps_r' n_clusters=2\n",
      "Silhouette:  0.3533233889165955\n",
      "Davies Bouldin:  1.0767255652685122\n",
      "Internal evaluation: attributes='normalized_star_energy', 'eps', 'eps_r' n_clusters=3\n",
      "Silhouette:  0.35073944239426263\n",
      "Davies Bouldin:  0.8593061365378304\n",
      "Internal evaluation: attributes='normalized_star_energy', 'eps', 'eps_r' n_clusters=4\n",
      "Silhouette:  0.3897502484951783\n",
      "Davies Bouldin:  0.8616048993639427\n"
     ]
    }
   ],
   "source": [
    "#gchop.JHistogram().decompose(gal)\n",
    "#abadi_results = gchop.models.JHistogram().decompose(gal)\n",
    "\n",
    "hclustering = HierarchicalClustering(comp)\n",
    "clustering_results = hclustering.run_all()\n",
    "\n",
    "# Internal evaluation\n",
    "internal_evaluation = Internal(comp)\n",
    "for row_name, row in clustering_results.iterrows():\n",
    "    for idy, results in enumerate(row):\n",
    "\n",
    "        with open('Internal evaluation results.txt', 'a') as f:\n",
    "            column_name = clustering_results.columns[idy]\n",
    "            real_row_name = row_name[1:-1]\n",
    "\n",
    "            title = f\"Internal evaluation: attributes={real_row_name} n_clusters={column_name}\"\n",
    "            print(title)\n",
    "            f.write(f\"attributes={real_row_name} n_clusters={column_name}\\n\")\n",
    "            print(\"Silhouette: \", internal_evaluation.silhouette(results))\n",
    "            f.write(f\"Silhouette: {internal_evaluation.silhouette(results)}\\n\")\n",
    "            print(\"Davies Bouldin: \", internal_evaluation.davies_bouldin(results))\n",
    "            f.write(f\"Davies Bouldin: {internal_evaluation.davies_bouldin(results)}\\n\\n\")\n",
    "            \n",
    "            #Reduced data set to be able to test stuff locally\n",
    "            x, y, z = np.array(comp.x_clean[:100]).T\n",
    "\n",
    "            #----Create graphs----\n",
    "            \n",
    "            #import matplotlib.pyplot as plt\n",
    "            #fig = plt.figure()\n",
    "            #ax = fig.add_subplot(projection='3d')\n",
    "            #ax.scatter(x, y ,z, c=clustering_results[column_name][row_name])\n",
    "            #ax.set_title(title)\n",
    "\n",
    "            #----------------------\n",
    "            \n",
    "            # No puedo correr localmente\n",
    "            #gal.plot.pairplot(attributes=[\"x\", \"y\", \"z\"], labels=results)\n",
    "            \n",
    "            #import pickle\n",
    "            #pickle.dump(fig, open(title+'.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "\n",
    "            import joblib\n",
    "            import pandas\n",
    "            #Doble check que los nombres de las columnas esten bien\n",
    "            data_to_graph = pandas.DataFrame({'normalized_star_energy': x, 'eps': y, 'eps_r': z, 'label': results})\n",
    "            \n",
    "            joblib.dump(data_to_graph, title+'.data', compress=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d439a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = joblib.load(\"Internal evaluation: attributes='eps', 'eps_r', n_clusters=2\")\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
