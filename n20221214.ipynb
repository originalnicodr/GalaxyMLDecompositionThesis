{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef443fdd-226b-4511-8d80-ecd9fc5683f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import galaxychop as gchop\n",
    "\n",
    "\n",
    "#gal = gchop.preproc.center_and_align(gchop.io.read_hdf5(\"tests/datasets/gal394242.h5\"))\n",
    "gal = gchop.preproc.center_and_align(gchop.io.read_hdf5(\"tests/datasets/galaxy_TNG_611399.h5\"))\n",
    "\n",
    "comp = gchop.models.AutoGaussianMixture(n_jobs=-2).decompose(gal)\n",
    "\n",
    "#gchop.models.GaussianMixture().get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07526877-2659-4518-8e93-95813728f0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Components length=272647, labels={'Warm disk', 'Halo', nan, 'Bulge', 'Cold disk'}, probabilities=True, lmap=True>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw_2d_graph(gal, labels, title, save_path):\n",
    "    fig1 = gal.plot.pairplot(attributes=[\"x\", \"y\", \"z\"], labels=labels).fig #lmap={0: \"disk\", 1: \"halo\"}\n",
    "    #ax1 = fig1.gca()\n",
    "    #ax1.set_title(title)\n",
    "    fig1.suptitle(title)\n",
    "    fig1.savefig(save_path+'- pairplot.png', bbox_inches='tight')\n",
    "\n",
    "    fig2 = gal.plot.circ_pairplot(labels=labels, attributes=['normalized_star_energy', 'eps', 'eps_r']).fig\n",
    "    #ax2 = fig2.gca()\n",
    "    #ax2.set_title(title)\n",
    "    fig2.suptitle(title)\n",
    "    fig2.savefig(save_path+'- circ_pairplot.png', bbox_inches='tight')\n",
    "\n",
    "def draw_3d_graph(normalized_star_energy, eps, eps_r, labels, title, save_path):\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(normalized_star_energy, eps, eps_r, c=labels)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    fig.savefig(save_path+'.png', bbox_inches='tight')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#draw_2d_graph(gal, comp, \"test_galaxia\", \"\")\n",
    "normalized_star_energy, eps, eps_r = np.array(comp.x_clean).T\n",
    "\n",
    "draw_2d_graph(gal, comp, \"testeando\", \"\")\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "#comp.describe()\n",
    "#circ = gchop.preproc.jcirc(gal)\n",
    "#circ.as_dict().keys()\n",
    "#circ.as_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "135cedac-a2df-46b5-b6d0-762ce5031f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10., 11., 12., nan, 13., 14.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1022f741-e32b-47b5-b9c3-85bd13961f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd2b1ab1-0518-48b1-8bf8-4786b9d0ffb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['normalized_star_energy', 'normalized_star_Jz', 'eps', 'eps_r'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3a67c17-2c92-4222-a81c-97486800007a",
   "metadata": {},
   "source": [
    "- Hacete el cluster jerarquico\n",
    "- Barre 2,3,4 y 5 componentes ['normalized_star_energy', 'eps', 'eps_r']\n",
    "- Barre usar todas combinaciones de\n",
    "- Sacale todas las metricas que ya tenes\n",
    "- Graficalo\n",
    "- Y todo comparalo paso a paso con Si los elementos son 2 con JHistogram, mas de eso comparalo con AutoGausian\n",
    "- Acordate de fijar semillas siempre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc5e256-928a-46d4-8c29-db273f9bcd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "from typing import Optional, List\n",
    "import numpy as np\n",
    "\n",
    "class ClusteringMethod:\n",
    "    pass\n",
    "class HierarchicalClustering(ClusteringMethod):\n",
    "    def __init__(self, comp):\n",
    "        self._comp = comp\n",
    "        self._has_probs = comp.probabilities is not None\n",
    "        \n",
    "    def run(self, n_clusters: int = 4, linkage: str = 'ward', attributes: Optional[List[int]] = None):\n",
    "        attribute_indeces = range(0, len(self._comp.attributes)) if attributes is None else attributes\n",
    "        galaxy_data = self._prepare_data(attribute_indeces)\n",
    "        clustering = sklearn.cluster.AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
    "        clustering.fit(galaxy_data)\n",
    "        \n",
    "        return np.array(clustering.labels_)\n",
    "    \n",
    "    def run_all(self, linkage: str = 'ward'):\n",
    "        all_attributes = self._comp.attributes\n",
    "        results = []\n",
    "        index = []\n",
    "        x = 0\n",
    "        for n, amount_attributes in enumerate(range(1, len(all_attributes)+1)):\n",
    "            combined_attributes = list(itertools.combinations(enumerate(all_attributes), amount_attributes))\n",
    "            for attributes in combined_attributes:\n",
    "                index.append(attributes)\n",
    "                results.append([])\n",
    "                for y, n_clusters in enumerate([2,3,4]):\n",
    "                    attribute_indices = [attribute[0] for attribute in attributes]\n",
    "                    results[x].append(self.run(n_clusters = n_clusters, attributes = attribute_indices))\n",
    "                x=x+1\n",
    "        \n",
    "        index = list(map(lambda a: str(tuple(map(lambda b: b[1], a))), index))\n",
    "        return pd.DataFrame(results,\n",
    "        index=pd.Index(index, name='Attributes'),\n",
    "        columns=pd.Index([2,3,4], name='n_clusters'))\n",
    "    \n",
    "    def _prepare_data(self, attribute_indices: List[int]):\n",
    "        data = [[t[i] for i in attribute_indices] for t in self._comp.x_clean]\n",
    "        attributes = [self._comp.attributes[i] for i in attribute_indices]\n",
    "        \n",
    "        galaxy_data = pd.DataFrame(data, columns = attributes)\n",
    "        #Reduced data set to be able to test stuff locally\n",
    "        galaxy_data = galaxy_data.head(100)\n",
    "        return galaxy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f20b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import galaxychop as gchop\n",
    "\n",
    "gal = gchop.preproc.center_and_align(gchop.io.read_hdf5(\"tests/datasets/gal394242.h5\"))\n",
    "\n",
    "comp = gchop.models.AutoGaussianMixture(n_jobs=-2).decompose(gal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "28f1f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hclustering = HierarchicalClustering(comp)\n",
    "#hclustering.run()\n",
    "#clustering_results = hclustering.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f09dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Internal:\n",
    "    \"\"\"Internal evaluation indexes.\n",
    "    \n",
    "    This class contains methods used for internal evaluation of clustering results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    comp: Components\n",
    "        The components of a galaxy.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, comp):\n",
    "        self._comp = comp\n",
    "        self._has_probs = comp.probabilities is not None\n",
    "\n",
    "    def silhouette(self, labels, **kwars):\n",
    "        \"\"\"The silhouette value is a measure of how similar an object is to its own cluster (cohesion)\n",
    "        compared to other clusters (separation). The silhouette ranges from âˆ’1 to +1,\n",
    "        where a high value indicates that the object is well matched to its own cluster and\n",
    "        poorly matched to neighboring clusters. If most objects have a high value,\n",
    "        then the clustering configuration is appropriate. If many points have a low or negative value,\n",
    "        then the clustering configuration may have too many or too few clusters.\n",
    "        \"\"\"\n",
    "        \n",
    "        #Reduced data set to be able to test stuff locally\n",
    "        galaxy_data = pd.DataFrame(self._comp.x_clean, columns = self._comp.attributes).head(100)\n",
    "        return sklearn.metrics.silhouette_score(galaxy_data, labels, **kwars)\n",
    "\n",
    "    def davies_bouldin(self, labels, **kwars):\n",
    "        \"\"\"Validates how well the clustering has been done is made using quantities and\n",
    "        features inherent to the dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        #Reduced data set to be able to test stuff locally\n",
    "        galaxy_data = pd.DataFrame(self._comp.x_clean, columns = self._comp.attributes).head(100)\n",
    "        return sklearn.metrics.davies_bouldin_score(galaxy_data, labels, **kwars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18997ecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HierarchicalClustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#gchop.JHistogram().decompose(gal)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#abadi_results = gchop.models.JHistogram().decompose(gal)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m hclustering \u001b[39m=\u001b[39m HierarchicalClustering(comp)\n\u001b[1;32m      5\u001b[0m clustering_results \u001b[39m=\u001b[39m hclustering\u001b[39m.\u001b[39mrun_all()\n\u001b[1;32m      7\u001b[0m \u001b[39m# Internal evaluation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HierarchicalClustering' is not defined"
     ]
    }
   ],
   "source": [
    "#gchop.JHistogram().decompose(gal)\n",
    "#abadi_results = gchop.models.JHistogram().decompose(gal)\n",
    "\n",
    "hclustering = HierarchicalClustering(comp)\n",
    "clustering_results = hclustering.run_all()\n",
    "\n",
    "# Internal evaluation\n",
    "internal_evaluation = Internal(comp)\n",
    "for row_name, row in clustering_results.iterrows():\n",
    "    for idy, results in enumerate(row):\n",
    "\n",
    "        with open('Internal evaluation results.txt', 'a') as f:\n",
    "            column_name = clustering_results.columns[idy]\n",
    "            real_row_name = row_name[1:-1]\n",
    "\n",
    "            title = f\"Internal evaluation: attributes={real_row_name} n_clusters={column_name}\"\n",
    "            print(title)\n",
    "            f.write(f\"attributes={real_row_name} n_clusters={column_name}\\n\")\n",
    "            print(\"Silhouette: \", internal_evaluation.silhouette(results))\n",
    "            f.write(f\"Silhouette: {internal_evaluation.silhouette(results)}\\n\")\n",
    "            print(\"Davies Bouldin: \", internal_evaluation.davies_bouldin(results))\n",
    "            f.write(f\"Davies Bouldin: {internal_evaluation.davies_bouldin(results)}\\n\\n\")\n",
    "            \n",
    "            #Reduced data set to be able to test stuff locally\n",
    "            x, y, z = np.array(comp.x_clean[:100]).T\n",
    "\n",
    "            #----Create graphs----\n",
    "            \n",
    "            #import matplotlib.pyplot as plt\n",
    "            #fig = plt.figure()\n",
    "            #ax = fig.add_subplot(projection='3d')\n",
    "            #ax.scatter(x, y ,z, c=clustering_results[column_name][row_name])\n",
    "            #ax.set_title(title)\n",
    "\n",
    "            #----------------------\n",
    "            \n",
    "            # No puedo correr localmente\n",
    "            #gal.plot.pairplot(attributes=[\"x\", \"y\", \"z\"], labels=results)\n",
    "            \n",
    "            #import pickle\n",
    "            #pickle.dump(fig, open(title+'.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "\n",
    "            import joblib\n",
    "            import pandas\n",
    "            #Doble check que los nombres de las columnas esten bien\n",
    "            data_to_graph = pandas.DataFrame({'normalized_star_energy': x, 'eps': y, 'eps_r': z, 'label': results})\n",
    "            \n",
    "            joblib.dump(data_to_graph, title+'.data', compress=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d439a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', n_clusters=2\n",
      "Silhouette:  0.14661494321943136\n",
      "Davies Bouldin:  2.3750366488862755\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', n_clusters=3\n",
      "Silhouette:  -0.033392931529375385\n",
      "Davies Bouldin:  3.773401328217627\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', n_clusters=4\n",
      "Silhouette:  -0.05205638286980453\n",
      "Davies Bouldin:  19.23301301245819\n",
      "Internal evaluation - gal394242.h5 : attributes='eps', n_clusters=2\n",
      "Silhouette:  0.36219074913930727\n",
      "Davies Bouldin:  1.0492050903541206\n",
      "Internal evaluation - gal394242.h5 : attributes='eps', n_clusters=3\n",
      "Silhouette:  0.29769338203660356\n",
      "Davies Bouldin:  1.1408448875408992\n",
      "Internal evaluation - gal394242.h5 : attributes='eps', n_clusters=4\n",
      "Silhouette:  0.23832918224694713\n",
      "Davies Bouldin:  1.3328401769480185\n",
      "Internal evaluation - gal394242.h5 : attributes='eps_r', n_clusters=2\n",
      "Silhouette:  0.3479039143915803\n",
      "Davies Bouldin:  1.436308611433696\n",
      "Internal evaluation - gal394242.h5 : attributes='eps_r', n_clusters=3\n",
      "Silhouette:  0.18025039820354993\n",
      "Davies Bouldin:  1.78337689904439\n",
      "Internal evaluation - gal394242.h5 : attributes='eps_r', n_clusters=4\n",
      "Silhouette:  0.09682942585320344\n",
      "Davies Bouldin:  2.3142306983857313\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', 'eps' n_clusters=2\n",
      "Silhouette:  0.3644591005213234\n",
      "Davies Bouldin:  1.0385581985436316\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', 'eps' n_clusters=3\n",
      "Silhouette:  0.3161788023073164\n",
      "Davies Bouldin:  1.0045156107060855\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', 'eps' n_clusters=4\n",
      "Silhouette:  0.2882112778710159\n",
      "Davies Bouldin:  1.117713268140147\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', 'eps_r' n_clusters=2\n",
      "Silhouette:  0.3479039143915803\n",
      "Davies Bouldin:  1.436308611433696\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', 'eps_r' n_clusters=3\n",
      "Silhouette:  0.18025039820354993\n",
      "Davies Bouldin:  1.78337689904439\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', 'eps_r' n_clusters=4\n",
      "Silhouette:  0.09682942585320344\n",
      "Davies Bouldin:  2.3142306983857313\n",
      "Internal evaluation - gal394242.h5 : attributes='eps', 'eps_r' n_clusters=2\n",
      "Silhouette:  0.3533233889165955\n",
      "Davies Bouldin:  1.0767255652685122\n",
      "Internal evaluation - gal394242.h5 : attributes='eps', 'eps_r' n_clusters=3\n",
      "Silhouette:  0.35073944239426263\n",
      "Davies Bouldin:  0.8593061365378304\n",
      "Internal evaluation - gal394242.h5 : attributes='eps', 'eps_r' n_clusters=4\n",
      "Silhouette:  0.3897502484951783\n",
      "Davies Bouldin:  0.8616048993639427\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', 'eps', 'eps_r' n_clusters=2\n",
      "Silhouette:  0.3533233889165955\n",
      "Davies Bouldin:  1.0767255652685122\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', 'eps', 'eps_r' n_clusters=3\n",
      "Silhouette:  0.35073944239426263\n",
      "Davies Bouldin:  0.8593061365378304\n",
      "Internal evaluation - gal394242.h5 : attributes='normalized_star_energy', 'eps', 'eps_r' n_clusters=4\n",
      "Silhouette:  0.3897502484951783\n",
      "Davies Bouldin:  0.8616048993639427\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', n_clusters=2\n",
      "Silhouette:  0.14661494321943136\n",
      "Davies Bouldin:  2.3750366488862755\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', n_clusters=3\n",
      "Silhouette:  -0.033392931529375385\n",
      "Davies Bouldin:  3.773401328217627\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', n_clusters=4\n",
      "Silhouette:  -0.05205638286980453\n",
      "Davies Bouldin:  19.23301301245819\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='eps', n_clusters=2\n",
      "Silhouette:  0.36219074913930727\n",
      "Davies Bouldin:  1.0492050903541206\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='eps', n_clusters=3\n",
      "Silhouette:  0.29769338203660356\n",
      "Davies Bouldin:  1.1408448875408992\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='eps', n_clusters=4\n",
      "Silhouette:  0.23832918224694713\n",
      "Davies Bouldin:  1.3328401769480185\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='eps_r', n_clusters=2\n",
      "Silhouette:  0.3479039143915803\n",
      "Davies Bouldin:  1.436308611433696\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='eps_r', n_clusters=3\n",
      "Silhouette:  0.18025039820354993\n",
      "Davies Bouldin:  1.78337689904439\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='eps_r', n_clusters=4\n",
      "Silhouette:  0.09682942585320344\n",
      "Davies Bouldin:  2.3142306983857313\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', 'eps' n_clusters=2\n",
      "Silhouette:  0.3644591005213234\n",
      "Davies Bouldin:  1.0385581985436316\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', 'eps' n_clusters=3\n",
      "Silhouette:  0.3161788023073164\n",
      "Davies Bouldin:  1.0045156107060855\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', 'eps' n_clusters=4\n",
      "Silhouette:  0.2882112778710159\n",
      "Davies Bouldin:  1.117713268140147\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', 'eps_r' n_clusters=2\n",
      "Silhouette:  0.3479039143915803\n",
      "Davies Bouldin:  1.436308611433696\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', 'eps_r' n_clusters=3\n",
      "Silhouette:  0.18025039820354993\n",
      "Davies Bouldin:  1.78337689904439\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', 'eps_r' n_clusters=4\n",
      "Silhouette:  0.09682942585320344\n",
      "Davies Bouldin:  2.3142306983857313\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='eps', 'eps_r' n_clusters=2\n",
      "Silhouette:  0.3533233889165955\n",
      "Davies Bouldin:  1.0767255652685122\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='eps', 'eps_r' n_clusters=3\n",
      "Silhouette:  0.35073944239426263\n",
      "Davies Bouldin:  0.8593061365378304\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='eps', 'eps_r' n_clusters=4\n",
      "Silhouette:  0.3897502484951783\n",
      "Davies Bouldin:  0.8616048993639427\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', 'eps', 'eps_r' n_clusters=2\n",
      "Silhouette:  0.3533233889165955\n",
      "Davies Bouldin:  1.0767255652685122\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', 'eps', 'eps_r' n_clusters=3\n",
      "Silhouette:  0.35073944239426263\n",
      "Davies Bouldin:  0.8593061365378304\n",
      "Internal evaluation - gal394242 (copy).h5 : attributes='normalized_star_energy', 'eps', 'eps_r' n_clusters=4\n",
      "Silhouette:  0.3897502484951783\n",
      "Davies Bouldin:  0.8616048993639427\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import galaxychop as gchop\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "from typing import Optional, List\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def analyze_galaxy(file_name, dataset_directory, results_path='results'):\n",
    "    gal = gchop.preproc.center_and_align(gchop.io.read_hdf5(dataset_directory+'/'+file_name))\n",
    "    comp = gchop.models.AutoGaussianMixture(n_jobs=-2).decompose(gal)\n",
    "\n",
    "    hclustering = HierarchicalClustering(comp)\n",
    "    clustering_results = hclustering.run_all()\n",
    "\n",
    "    if not os.path.exists(results_path+'/'+file_name+'/'):\n",
    "        os.makedirs(results_path+'/'+file_name+'/')\n",
    "\n",
    "    # Internal evaluation\n",
    "    internal_evaluation = Internal(comp)\n",
    "    for row_name, row in clustering_results.iterrows():\n",
    "        for idy, results in enumerate(row):\n",
    "\n",
    "            \n",
    "            with open(results_path+'/'+file_name+'/Internal evaluation results.txt', 'a') as f:\n",
    "                column_name = clustering_results.columns[idy]\n",
    "                real_row_name = row_name[1:-1]\n",
    "\n",
    "                title = f\"{file_name} : attributes={real_row_name} n_clusters={column_name}\"\n",
    "                print(title)\n",
    "                f.write(f\"attributes={real_row_name} n_clusters={column_name}\\n\")\n",
    "                print(\"Silhouette: \", internal_evaluation.silhouette(results))\n",
    "                f.write(f\"Silhouette: {internal_evaluation.silhouette(results)}\\n\")\n",
    "                print(\"Davies Bouldin: \", internal_evaluation.davies_bouldin(results))\n",
    "                f.write(f\"Davies Bouldin: {internal_evaluation.davies_bouldin(results)}\\n\\n\")\n",
    "                \n",
    "                #Reduced data set to be able to test stuff locally\n",
    "                x, y, z = np.array(comp.x_clean[:100]).T\n",
    "\n",
    "                #----Create graphs----\n",
    "                \n",
    "                #import matplotlib.pyplot as plt\n",
    "                #fig = plt.figure()\n",
    "                #ax = fig.add_subplot(projection='3d')\n",
    "                #ax.scatter(x, y ,z, c=clustering_results[column_name][row_name])\n",
    "                #ax.set_title(title)\n",
    "\n",
    "                #----------------------\n",
    "                \n",
    "                # No puedo correr localmente\n",
    "                #gal.plot.pairplot(attributes=[\"x\", \"y\", \"z\"], labels=results)\n",
    "                \n",
    "                #import pickle\n",
    "                #pickle.dump(fig, open(title+'.pickle', 'wb')) # This is for Python 3 - py2 may need `file` instead of `open`\n",
    "\n",
    "                import joblib\n",
    "                import pandas\n",
    "                #Doble check que los nombres de las columnas esten bien\n",
    "                data_to_graph = pandas.DataFrame({'normalized_star_energy': x, 'eps': y, 'eps_r': z, 'label': results})\n",
    "                \n",
    "                joblib.dump(data_to_graph, results_path+'/'+file_name+'/'+title+'.data', compress=3)\n",
    "\n",
    "directory_name = \"tests/datasets/\"\n",
    "\n",
    "for dirpath,_,filenames in os.walk(directory_name):\n",
    "    filenames = [ fi for fi in filenames if fi.endswith(\".h5\") ]\n",
    "    for file_name in filenames:\n",
    "        analyze_galaxy(file_name, directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea0ae58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
